{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "satisfactory-green",
   "metadata": {},
   "source": [
    "# Breast-cancer Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "thirty-loading",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "load = load_breast_cancer()\n",
    "cancer = pd.DataFrame(load.data, columns=load.feature_names)\n",
    "target = pd.DataFrame(load.target, columns =['target'])\n",
    "\n",
    "# Split 80 : 20\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(cancer, target, train_size = 0.8, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collect-philippines",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "vanilla-weight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=600)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "model = MLPClassifier(max_iter = 600)\n",
    "\n",
    "model.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interior-carrier",
   "metadata": {},
   "source": [
    "c:\\users\\annisa rahim\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
    "  % self.max_iter, ConvergenceWarning)\n",
    "  \n",
    "karena stochastic maybe. cenderung baru aman saat max iter 600\n",
    "MLPClassifier(max_iter=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "surprising-bidding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.989010989010989\n",
      "F1 score:  0.9912739965095986\n"
     ]
    }
   ],
   "source": [
    "predict_train = model.predict(X_train)\n",
    "\n",
    "acc = accuracy_score(y_train, predict_train)\n",
    "f1 = f1_score(y_train, predict_train)\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "persistent-brook",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9122807017543859\n",
      "F1 score:  0.9253731343283582\n"
     ]
    }
   ],
   "source": [
    "predict_test = model.predict(X_valid)\n",
    "\n",
    "acc = accuracy_score(y_valid, predict_test)\n",
    "f1 = f1_score(y_valid, predict_test)\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-registrar",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fresh-victorian",
   "metadata": {},
   "source": [
    "### Standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "political-print",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=600)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)\n",
    "\n",
    "model.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ordered-creature",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n",
      "F1 score:  1.0\n"
     ]
    }
   ],
   "source": [
    "predict_train = model.predict(X_train)\n",
    "\n",
    "acc = accuracy_score(y_train, predict_train)\n",
    "f1 = f1_score(y_train, predict_train)\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "raising-function",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9649122807017544\n",
      "F1 score:  0.9726027397260274\n"
     ]
    }
   ],
   "source": [
    "predict_test = model.predict(X_valid)\n",
    "\n",
    "acc = accuracy_score(y_valid, predict_test)\n",
    "f1 = f1_score(y_valid, predict_test)\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-festival",
   "metadata": {},
   "source": [
    "meningkat!\n",
    "### MinMax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "advisory-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "load = load_breast_cancer()\n",
    "cancer = pd.DataFrame(load.data, columns=load.feature_names)\n",
    "target = pd.DataFrame(load.target, columns =['target'])\n",
    "\n",
    "# Split 80 : 20\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(cancer, target, train_size = 0.8, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "checked-medicare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=600)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)\n",
    "\n",
    "model.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "cellular-parliament",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.989010989010989\n",
      "F1 score:  0.9913043478260869\n"
     ]
    }
   ],
   "source": [
    "predict_train = model.predict(X_train)\n",
    "\n",
    "acc = accuracy_score(y_train, predict_train)\n",
    "f1 = f1_score(y_train, predict_train)\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "flush-romance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9210526315789473\n",
      "F1 score:  0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "predict_test = model.predict(X_valid)\n",
    "\n",
    "acc = accuracy_score(y_valid, predict_test)\n",
    "f1 = f1_score(y_valid, predict_test)\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-routine",
   "metadata": {},
   "source": [
    "Lumayan\n",
    "\n",
    "Kesimpulan: \n",
    "- data breast cancer better saat discaling menggunakan standard scaler\n",
    "- lumayan saat menggunakan minmax (akurasi lokal lebih baik daripada tidak discale, tapi akurasi prediksi menurun) \n",
    "\n",
    "Note: terkadang pemodelan MLPClassifier mengalami confergence warning dengan max iter default 200, tapi terkadang juga tidak. Hasil setiap pemodelan MLPClassifier dapat menghasilkan akurasi yang berbeda-beda, mungkin karena menggunakan stochastic, setiap pembentukan model bisa menghasilkan model yang berbeda."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-shore",
   "metadata": {},
   "source": [
    "# Tennis Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "average-shame",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  play\n",
       "3  yes\n",
       "7   no\n",
       "6  yes"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tennis = pd.read_csv('datasets/PlayTennis.csv')\n",
    "X_tennis = tennis.drop(['play'],axis=1)\n",
    "y_tennis = pd.DataFrame(tennis['play'])\n",
    "\n",
    "# Split 80 : 20\n",
    "X_train_tennis, X_valid_tennis, y_train_tennis, y_valid_tennis = train_test_split(X_tennis, y_tennis, train_size = 0.8, test_size = 0.2, random_state=1)\n",
    "y_valid_tennis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "known-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cond = (X_train_tennis.dtypes == 'object')\n",
    "object_cols = list(cond[cond].index)\n",
    "\n",
    "label_X_train = X_train_tennis.copy()\n",
    "label_X_valid = X_valid_tennis.copy()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for col in object_cols:\n",
    "    label_X_train[col] = label_encoder.fit_transform(X_train_tennis[col])\n",
    "    label_X_valid[col] = label_encoder.transform(X_valid_tennis[col])\n",
    "\n",
    "# In case needed\n",
    "label_y_train = label_encoder.fit_transform(y_train_tennis.values.ravel())\n",
    "label_y_valid = label_encoder.transform(y_valid_tennis.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "executive-stockholm",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=600)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "model = MLPClassifier(max_iter=600)\n",
    "\n",
    "model.fit(label_X_train,label_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cooked-movement",
   "metadata": {},
   "source": [
    "pada awalnya dia juga eror seperti ini:\n",
    "\n",
    "c:\\users\\annisa rahim\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:617: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
    "  % self.max_iter, ConvergenceWarning)\n",
    "  \n",
    " baru berhasil saat MLPClassifier(max_iter=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "sapphire-month",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n",
      "F1 score:  1.0\n"
     ]
    }
   ],
   "source": [
    "predict_train = model.predict(label_X_train)\n",
    "\n",
    "acc = accuracy_score(label_y_train, predict_train)\n",
    "f1 = f1_score(label_y_train, predict_train)\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "durable-bronze",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6666666666666666\n",
      "F1 score:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "predict_test = model.predict(label_X_valid)\n",
    "\n",
    "acc = accuracy_score(label_y_valid, predict_test)\n",
    "f1 = f1_score(label_y_valid, predict_test)\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-desire",
   "metadata": {},
   "source": [
    "HMM keren sekali!! Sempat 1 1 utk test prediction data. Tapi terkadang menjadi 0.666"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "intelligent-armenia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=600)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MINMAX SCALER\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "label_X_train = scaler.fit_transform(label_X_train)\n",
    "label_X_valid = scaler.fit_transform(label_X_valid)\n",
    "model.fit(label_X_train,label_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "basic-institution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n",
      "F1 score:  1.0\n"
     ]
    }
   ],
   "source": [
    "predict_train = model.predict(label_X_train)\n",
    "\n",
    "acc = accuracy_score(label_y_train, predict_train)\n",
    "f1 = f1_score(label_y_train, predict_train)\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "frozen-ebony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6666666666666666\n",
      "F1 score:  0.8\n"
     ]
    }
   ],
   "source": [
    "predict_test = model.predict(label_X_valid)\n",
    "\n",
    "acc = accuracy_score(label_y_valid, predict_test)\n",
    "f1 = f1_score(label_y_valid, predict_test)\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "opposed-trust",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(max_iter=600)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STANDARD SCALER\n",
    "tennis = pd.read_csv('datasets/PlayTennis.csv')\n",
    "X_tennis = tennis.drop(['play'],axis=1)\n",
    "y_tennis = pd.DataFrame(tennis['play'])\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cond = (X_train_tennis.dtypes == 'object')\n",
    "object_cols = list(cond[cond].index)\n",
    "\n",
    "label_X_train = X_train_tennis.copy()\n",
    "label_X_valid = X_valid_tennis.copy()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for col in object_cols:\n",
    "    label_X_train[col] = label_encoder.fit_transform(X_train_tennis[col])\n",
    "    label_X_valid[col] = label_encoder.transform(X_valid_tennis[col])\n",
    "\n",
    "# In case needed\n",
    "label_y_train = label_encoder.fit_transform(y_train_tennis.values.ravel())\n",
    "label_y_valid = label_encoder.transform(y_valid_tennis.values.ravel())\n",
    "\n",
    "# Split 80 : 20\n",
    "X_train_tennis, X_valid_tennis, y_train_tennis, y_valid_tennis = train_test_split(X_tennis, y_tennis, train_size = 0.8, test_size = 0.2, random_state=1)\n",
    "y_valid_tennis\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "label_X_train = scaler.fit_transform(label_X_train)\n",
    "label_X_valid = scaler.fit_transform(label_X_valid)\n",
    "\n",
    "model.fit(label_X_train,label_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "documented-animation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n",
      "F1 score:  1.0\n"
     ]
    }
   ],
   "source": [
    "predict_train = model.predict(label_X_train)\n",
    "\n",
    "acc = accuracy_score(label_y_train, predict_train)\n",
    "f1 = f1_score(label_y_train, predict_train)\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "laughing-adrian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6666666666666666\n",
      "F1 score:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "predict_test = model.predict(label_X_valid)\n",
    "\n",
    "acc = accuracy_score(label_y_valid, predict_test)\n",
    "f1 = f1_score(label_y_valid, predict_test)\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "large-parks",
   "metadata": {},
   "source": [
    "saat diberi standard scaler malah menurun."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "internal-raise",
   "metadata": {},
   "source": [
    "# Kesimpulan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aerial-thesaurus",
   "metadata": {},
   "source": [
    "Cenderung tidak mencapai konvergen saat max iter < 600. Saat sudah mencapai konvergen, dapat menjadi sangat akurat (accuracy dan f1 bernilai 1 untuk semua data lokal dan data uji"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
