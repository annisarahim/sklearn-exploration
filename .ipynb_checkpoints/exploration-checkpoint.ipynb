{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scikit-learn exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Made by:\n",
    "- Annisa Rahim / 13518089\n",
    "- Stefanus Gusega Gunawan / 13518149"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast-Cancer Dataset\n",
    "\n",
    "Load the datasets first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>17.99</td>\n",
       "      <td>20.66</td>\n",
       "      <td>117.80</td>\n",
       "      <td>991.7</td>\n",
       "      <td>0.10360</td>\n",
       "      <td>0.13040</td>\n",
       "      <td>0.120100</td>\n",
       "      <td>0.088240</td>\n",
       "      <td>0.1992</td>\n",
       "      <td>0.06069</td>\n",
       "      <td>...</td>\n",
       "      <td>21.080</td>\n",
       "      <td>25.41</td>\n",
       "      <td>138.10</td>\n",
       "      <td>1349.0</td>\n",
       "      <td>0.14820</td>\n",
       "      <td>0.37350</td>\n",
       "      <td>0.33010</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.3060</td>\n",
       "      <td>0.08503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.198000</td>\n",
       "      <td>0.104300</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.40000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>9.00</td>\n",
       "      <td>14.40</td>\n",
       "      <td>56.36</td>\n",
       "      <td>246.3</td>\n",
       "      <td>0.07005</td>\n",
       "      <td>0.03116</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>0.003472</td>\n",
       "      <td>0.1788</td>\n",
       "      <td>0.06833</td>\n",
       "      <td>...</td>\n",
       "      <td>9.699</td>\n",
       "      <td>20.07</td>\n",
       "      <td>60.90</td>\n",
       "      <td>285.5</td>\n",
       "      <td>0.09861</td>\n",
       "      <td>0.05232</td>\n",
       "      <td>0.01472</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.07804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>12.21</td>\n",
       "      <td>14.09</td>\n",
       "      <td>78.78</td>\n",
       "      <td>462.0</td>\n",
       "      <td>0.08108</td>\n",
       "      <td>0.07823</td>\n",
       "      <td>0.068390</td>\n",
       "      <td>0.025340</td>\n",
       "      <td>0.1646</td>\n",
       "      <td>0.06154</td>\n",
       "      <td>...</td>\n",
       "      <td>13.130</td>\n",
       "      <td>19.29</td>\n",
       "      <td>87.65</td>\n",
       "      <td>529.9</td>\n",
       "      <td>0.10260</td>\n",
       "      <td>0.24310</td>\n",
       "      <td>0.30760</td>\n",
       "      <td>0.09140</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.08824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>12.34</td>\n",
       "      <td>14.95</td>\n",
       "      <td>78.29</td>\n",
       "      <td>469.1</td>\n",
       "      <td>0.08682</td>\n",
       "      <td>0.04571</td>\n",
       "      <td>0.021090</td>\n",
       "      <td>0.020540</td>\n",
       "      <td>0.1571</td>\n",
       "      <td>0.05708</td>\n",
       "      <td>...</td>\n",
       "      <td>13.180</td>\n",
       "      <td>16.85</td>\n",
       "      <td>84.11</td>\n",
       "      <td>533.1</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0.06744</td>\n",
       "      <td>0.04921</td>\n",
       "      <td>0.04793</td>\n",
       "      <td>0.2298</td>\n",
       "      <td>0.05974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>19.79</td>\n",
       "      <td>25.12</td>\n",
       "      <td>130.40</td>\n",
       "      <td>1192.0</td>\n",
       "      <td>0.10150</td>\n",
       "      <td>0.15890</td>\n",
       "      <td>0.254500</td>\n",
       "      <td>0.114900</td>\n",
       "      <td>0.2202</td>\n",
       "      <td>0.06113</td>\n",
       "      <td>...</td>\n",
       "      <td>22.630</td>\n",
       "      <td>33.58</td>\n",
       "      <td>148.70</td>\n",
       "      <td>1589.0</td>\n",
       "      <td>0.12750</td>\n",
       "      <td>0.38610</td>\n",
       "      <td>0.56730</td>\n",
       "      <td>0.17320</td>\n",
       "      <td>0.3305</td>\n",
       "      <td>0.08465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>10.75</td>\n",
       "      <td>14.97</td>\n",
       "      <td>68.26</td>\n",
       "      <td>355.3</td>\n",
       "      <td>0.07793</td>\n",
       "      <td>0.05139</td>\n",
       "      <td>0.022510</td>\n",
       "      <td>0.007875</td>\n",
       "      <td>0.1399</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>...</td>\n",
       "      <td>11.950</td>\n",
       "      <td>20.72</td>\n",
       "      <td>77.79</td>\n",
       "      <td>441.2</td>\n",
       "      <td>0.10760</td>\n",
       "      <td>0.12230</td>\n",
       "      <td>0.09755</td>\n",
       "      <td>0.03413</td>\n",
       "      <td>0.2300</td>\n",
       "      <td>0.06769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>17.20</td>\n",
       "      <td>24.52</td>\n",
       "      <td>114.20</td>\n",
       "      <td>929.4</td>\n",
       "      <td>0.10710</td>\n",
       "      <td>0.18300</td>\n",
       "      <td>0.169200</td>\n",
       "      <td>0.079440</td>\n",
       "      <td>0.1927</td>\n",
       "      <td>0.06487</td>\n",
       "      <td>...</td>\n",
       "      <td>23.320</td>\n",
       "      <td>33.82</td>\n",
       "      <td>151.60</td>\n",
       "      <td>1681.0</td>\n",
       "      <td>0.15850</td>\n",
       "      <td>0.73940</td>\n",
       "      <td>0.65660</td>\n",
       "      <td>0.18990</td>\n",
       "      <td>0.3313</td>\n",
       "      <td>0.13390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>14.03</td>\n",
       "      <td>21.25</td>\n",
       "      <td>89.79</td>\n",
       "      <td>603.4</td>\n",
       "      <td>0.09070</td>\n",
       "      <td>0.06945</td>\n",
       "      <td>0.014620</td>\n",
       "      <td>0.018960</td>\n",
       "      <td>0.1517</td>\n",
       "      <td>0.05835</td>\n",
       "      <td>...</td>\n",
       "      <td>15.330</td>\n",
       "      <td>30.28</td>\n",
       "      <td>98.27</td>\n",
       "      <td>715.5</td>\n",
       "      <td>0.12870</td>\n",
       "      <td>0.15130</td>\n",
       "      <td>0.06231</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.07617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>13.03</td>\n",
       "      <td>18.42</td>\n",
       "      <td>82.61</td>\n",
       "      <td>523.8</td>\n",
       "      <td>0.08983</td>\n",
       "      <td>0.03766</td>\n",
       "      <td>0.025620</td>\n",
       "      <td>0.029230</td>\n",
       "      <td>0.1467</td>\n",
       "      <td>0.05863</td>\n",
       "      <td>...</td>\n",
       "      <td>13.300</td>\n",
       "      <td>22.81</td>\n",
       "      <td>84.46</td>\n",
       "      <td>545.9</td>\n",
       "      <td>0.09701</td>\n",
       "      <td>0.04619</td>\n",
       "      <td>0.04833</td>\n",
       "      <td>0.05013</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>0.06169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>455 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "408        17.99         20.66          117.80      991.7          0.10360   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "307         9.00         14.40           56.36      246.3          0.07005   \n",
       "386        12.21         14.09           78.78      462.0          0.08108   \n",
       "404        12.34         14.95           78.29      469.1          0.08682   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "129        19.79         25.12          130.40     1192.0          0.10150   \n",
       "144        10.75         14.97           68.26      355.3          0.07793   \n",
       "72         17.20         24.52          114.20      929.4          0.10710   \n",
       "235        14.03         21.25           89.79      603.4          0.09070   \n",
       "37         13.03         18.42           82.61      523.8          0.08983   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "408           0.13040        0.120100             0.088240         0.1992   \n",
       "4             0.13280        0.198000             0.104300         0.1809   \n",
       "307           0.03116        0.003681             0.003472         0.1788   \n",
       "386           0.07823        0.068390             0.025340         0.1646   \n",
       "404           0.04571        0.021090             0.020540         0.1571   \n",
       "..                ...             ...                  ...            ...   \n",
       "129           0.15890        0.254500             0.114900         0.2202   \n",
       "144           0.05139        0.022510             0.007875         0.1399   \n",
       "72            0.18300        0.169200             0.079440         0.1927   \n",
       "235           0.06945        0.014620             0.018960         0.1517   \n",
       "37            0.03766        0.025620             0.029230         0.1467   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "408                 0.06069  ...        21.080          25.41   \n",
       "4                   0.05883  ...        22.540          16.67   \n",
       "307                 0.06833  ...         9.699          20.07   \n",
       "386                 0.06154  ...        13.130          19.29   \n",
       "404                 0.05708  ...        13.180          16.85   \n",
       "..                      ...  ...           ...            ...   \n",
       "129                 0.06113  ...        22.630          33.58   \n",
       "144                 0.05688  ...        11.950          20.72   \n",
       "72                  0.06487  ...        23.320          33.82   \n",
       "235                 0.05835  ...        15.330          30.28   \n",
       "37                  0.05863  ...        13.300          22.81   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "408           138.10      1349.0           0.14820            0.37350   \n",
       "4             152.20      1575.0           0.13740            0.20500   \n",
       "307            60.90       285.5           0.09861            0.05232   \n",
       "386            87.65       529.9           0.10260            0.24310   \n",
       "404            84.11       533.1           0.10480            0.06744   \n",
       "..               ...         ...               ...                ...   \n",
       "129           148.70      1589.0           0.12750            0.38610   \n",
       "144            77.79       441.2           0.10760            0.12230   \n",
       "72            151.60      1681.0           0.15850            0.73940   \n",
       "235            98.27       715.5           0.12870            0.15130   \n",
       "37             84.46       545.9           0.09701            0.04619   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "408          0.33010               0.19740          0.3060   \n",
       "4            0.40000               0.16250          0.2364   \n",
       "307          0.01472               0.01389          0.2991   \n",
       "386          0.30760               0.09140          0.2677   \n",
       "404          0.04921               0.04793          0.2298   \n",
       "..               ...                   ...             ...   \n",
       "129          0.56730               0.17320          0.3305   \n",
       "144          0.09755               0.03413          0.2300   \n",
       "72           0.65660               0.18990          0.3313   \n",
       "235          0.06231               0.07963          0.2226   \n",
       "37           0.04833               0.05013          0.1987   \n",
       "\n",
       "     worst fractal dimension  \n",
       "408                  0.08503  \n",
       "4                    0.07678  \n",
       "307                  0.07804  \n",
       "386                  0.08824  \n",
       "404                  0.05974  \n",
       "..                       ...  \n",
       "129                  0.08465  \n",
       "144                  0.06769  \n",
       "72                   0.13390  \n",
       "235                  0.07617  \n",
       "37                   0.06169  \n",
       "\n",
       "[455 rows x 30 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "load = load_breast_cancer()\n",
    "cancer = pd.DataFrame(load.data, columns=load.feature_names)\n",
    "target = pd.DataFrame(load.target, columns =['target'])\n",
    "\n",
    "# Split 80 : 20\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(cancer, target, train_size = 0.8, test_size = 0.2, random_state=1)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether there is missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_missing = [col for col in cancer.columns if (cancer[col].isnull().any())]\n",
    "cols_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train datasets\n",
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "classifier = DecisionTreeClassifier(random_state=1)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- worst perimeter <= 106.05\n",
      "|   |--- worst concave points <= 0.16\n",
      "|   |   |--- worst concave points <= 0.14\n",
      "|   |   |   |--- area error <= 48.98\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- area error >  48.98\n",
      "|   |   |   |   |--- worst radius <= 13.55\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- worst radius >  13.55\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |--- worst concave points >  0.14\n",
      "|   |   |   |--- worst texture <= 29.45\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- worst texture >  29.45\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |--- worst concave points >  0.16\n",
      "|   |   |--- worst texture <= 24.78\n",
      "|   |   |   |--- class: 1\n",
      "|   |   |--- worst texture >  24.78\n",
      "|   |   |   |--- class: 0\n",
      "|--- worst perimeter >  106.05\n",
      "|   |--- worst texture <= 20.65\n",
      "|   |   |--- worst perimeter <= 116.80\n",
      "|   |   |   |--- class: 1\n",
      "|   |   |--- worst perimeter >  116.80\n",
      "|   |   |   |--- mean smoothness <= 0.08\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- mean smoothness >  0.08\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |--- worst texture >  20.65\n",
      "|   |   |--- mean concave points <= 0.05\n",
      "|   |   |   |--- concave points error <= 0.01\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |   |--- concave points error >  0.01\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |--- mean concave points >  0.05\n",
      "|   |   |   |--- mean smoothness <= 0.08\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- mean smoothness >  0.08\n",
      "|   |   |   |   |--- class: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_text\n",
    "\n",
    "tree = export_text(classifier, feature_names = list(cancer.columns))\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give prediction to training data so we can see how good the model is. Compared to true value of training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model with Accuracy Metrics.\n",
    "\n",
    "$$\n",
    "Accuracy = \\frac {Number of Correct predictions}{Total number of predictions made}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_train_score = accuracy_score(y_train, predict_train)\n",
    "acc_train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model with F1 score Metrics. The metrics used based on this confusion matrix. F1 Score is the **_Harmonic Mean_** between precision and recall.\n",
    "<!-- ![Alt Text](image path \"title\") -->\n",
    "![Alt Text](https://miro.medium.com/max/700/1*OhEnS-T54Cz0YSTl_c3Dwg.jpeg \"Confusion Matrix\")\n",
    "\n",
    "$$\n",
    "Precision = \\frac {TruePositives}{TruePositives+FalsePositives}\n",
    "$$ <br>\n",
    "$$\n",
    "Recall = \\frac {TruePositives}{TruePositives+FalseNegatives}\n",
    "$$ <br>\n",
    "$$\n",
    "F1 = 2*(\\frac{1}{\\frac {1}{Precision} + \\frac {1}{Recall}}) = 2*(\\frac {TruePositives}{2TruePositives+FalsePositives+FalseNegatives})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_train_score = f1_score(y_train, predict_train)\n",
    "f1_train_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now predict the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_valid = classifier.predict(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model with Accuracy Metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_valid_score = accuracy_score(y_valid, predict_valid)\n",
    "acc_valid_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model with F1 Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9594594594594595"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_valid_score = f1_score(y_valid, predict_valid)\n",
    "f1_valid_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Id3Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model and print the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "worst perimeter <=105.15\n",
      "|   worst concave points <=0.14\n",
      "|   |   radius error <=0.64: 1 (249) \n",
      "|   |   radius error >0.64\n",
      "|   |   |   mean radius <=12.27: 0 (1) \n",
      "|   |   |   mean radius >12.27: 1 (2) \n",
      "|   worst concave points >0.14\n",
      "|   |   worst texture <=25.94: 1 (6) \n",
      "|   |   worst texture >25.94\n",
      "|   |   |   mean compactness <=0.12\n",
      "|   |   |   |   mean radius <=14.06: 1 (2) \n",
      "|   |   |   |   mean radius >14.06: 0 (1) \n",
      "|   |   |   mean compactness >0.12: 0 (5) \n",
      "worst perimeter >105.15\n",
      "|   worst concave points <=0.15\n",
      "|   |   worst texture <=19.91: 1 (13) \n",
      "|   |   worst texture >19.91\n",
      "|   |   |   worst radius <=16.80\n",
      "|   |   |   |   mean smoothness <=0.09: 1 (8) \n",
      "|   |   |   |   mean smoothness >0.09\n",
      "|   |   |   |   |   smoothness error <=0.00: 1 (2) \n",
      "|   |   |   |   |   smoothness error >0.00: 0 (5) \n",
      "|   |   |   worst radius >16.80\n",
      "|   |   |   |   worst concavity <=0.21\n",
      "|   |   |   |   |   mean texture <=21.26: 1 (2) \n",
      "|   |   |   |   |   mean texture >21.26: 0 (2) \n",
      "|   |   |   |   worst concavity >0.21: 0 (21) \n",
      "|   worst concave points >0.15\n",
      "|   |   mean texture <=15.35\n",
      "|   |   |   mean radius <=14.89: 1 (1) \n",
      "|   |   |   mean radius >14.89: 0 (3) \n",
      "|   |   mean texture >15.35: 0 (132) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "\n",
    "from id3 import Id3Estimator, export\n",
    "\n",
    "id3_model1 = Id3Estimator()\n",
    "\n",
    "id3_model1.fit(X_train, y_train.values.ravel()) # make it numpy 1D array, not a df\n",
    "\n",
    "# export text\n",
    "tree_text1 = export.export_text(id3_model1.tree_, feature_names=cancer.columns)\n",
    "\n",
    "print(tree_text1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model with Accuracy and F1 score metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n",
      "F1 score:  1.0\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation\n",
    "predict_train1 = id3_model1.predict(X_train)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(predict_train1, y_train))\n",
    "print(\"F1 score: \", f1_score(predict_train1, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model to test data with Accuracy and F1 score metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9385964912280702\n",
      "F1 score:  0.953020134228188\n"
     ]
    }
   ],
   "source": [
    "# Model Prediction\n",
    "predict_test1 = id3_model1.predict(X_valid)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(predict_test1,y_valid))\n",
    "print(\"F1 score: \", f1_score(predict_test1,y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=2, random_state=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Determine how many clusters\n",
    "n_clust = y_train['target'].nunique()\n",
    "\n",
    "kmeans_model_1 = KMeans(n_clusters=n_clust,random_state=1)\n",
    "kmeans_model_1.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the data train and data test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 1 0 1\n",
      " 0 0 1 1 0 0 0 0 1 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 1 0 0 1 1 0\n",
      " 0 0 1 0 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0\n",
      " 0 0 0 1 0 0 1 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 1\n",
      " 1 1 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1\n",
      " 1 1 0 0 0 1 1 0 0 0 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 1 0\n",
      " 1 0 0 0 0 0 1 0 1 0 0]\n",
      "     target\n",
      "408       0\n",
      "4         0\n",
      "307       1\n",
      "386       1\n",
      "404       1\n",
      "..      ...\n",
      "129       0\n",
      "144       1\n",
      "72        0\n",
      "235       1\n",
      "37        1\n",
      "\n",
      "[455 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "kmeans_predict_train = kmeans_model_1.predict(X_train)\n",
    "kmeans_predict_test = kmeans_model_1.predict(X_valid)\n",
    "print(kmeans_predict_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to switch the value from 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def switch(x: int) -> int:\n",
    "    if (x==0):\n",
    "        return x+1\n",
    "    elif (x==1):\n",
    "        return x-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluation with training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First clusterization accuracy: 0.15164835164835164\n",
      "First clusterization F1: 0.005154639175257732\n",
      "Second clusterization accuracy: 0.8483516483516483\n",
      "Second clusterization F1: 0.891679748822606\n"
     ]
    }
   ],
   "source": [
    "# Find out each cluster belong with which class\n",
    "\n",
    "# First clusterization using first prediction (k_means_train)\n",
    "# Calculate the accuracy and F1\n",
    "acc_train = accuracy_score(y_train, kmeans_predict_train)\n",
    "f1_train = f1_score(y_train, kmeans_predict_train)\n",
    "print(f\"First clusterization accuracy: {acc_train}\")\n",
    "print(f\"First clusterization F1: {f1_train}\")\n",
    "\n",
    "# Second clusterization: switch 0 to 1\n",
    "switched_train = pd.Series(kmeans_predict_train)\n",
    "fix = switched_train.apply(switch)\n",
    "acc_train1= accuracy_score(y_train, fix)\n",
    "f1_train2= f1_score(y_train, fix)\n",
    "print(f\"Second clusterization accuracy: {acc_train1}\")\n",
    "print(f\"Second clusterization F1: {f1_train2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance can be seen by the greatest metrics score. So the cluster 0 belongs to class of 1, cluster 1 belongs to class of 0. Now, for evaluation with validation data (datatest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First clusterization accuracy: 0.19298245614035087\n",
      "First clusterization F1: 0.005154639175257732\n",
      "Second clusterization accuracy: 0.8070175438596491\n",
      "Second clusterization F1: 0.8674698795180723\n"
     ]
    }
   ],
   "source": [
    "# First clusterization\n",
    "acc_valid = accuracy_score(y_valid, kmeans_predict_test)\n",
    "f1_valid = f1_score(y_valid, kmeans_predict_test)\n",
    "print(f\"First clusterization accuracy: {acc_valid}\")\n",
    "print(f\"First clusterization F1: {f1_train}\")\n",
    "\n",
    "# Second clusterization: switch 0 to 1\n",
    "switched_valid = pd.Series(kmeans_predict_test).apply(switch)\n",
    "acc_valid_switch = accuracy_score(y_valid, switched_valid)\n",
    "f1_valid_switch = f1_score(y_valid, switched_valid)\n",
    "print(f\"Second clusterization accuracy: {acc_valid_switch}\")\n",
    "print(f\"Second clusterization F1: {f1_valid_switch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as when we evaluate with training data, the second clusterization is better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling, soalnya kl gapake scaling atau max iter ga ditambah \n",
    "# dia ada ConvergenceWarning\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling the scaled dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model to train data with Accuracy and F1 score metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9912087912087912\n",
      "F1 score:  0.993006993006993\n"
     ]
    }
   ],
   "source": [
    "predict_train = model.predict(X_train)\n",
    "\n",
    "acc = accuracy_score(y_train, predict_train)\n",
    "f1 = f1_score(y_train, predict_train)\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model to test data with Accuracy and F1 score metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9736842105263158\n",
      "F1 score:  0.9793103448275863\n"
     ]
    }
   ],
   "source": [
    "predict_test = model.predict(X_valid)\n",
    "\n",
    "acc = accuracy_score(y_valid, predict_test)\n",
    "f1 = f1_score(y_valid, predict_test)\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no scaler & no max iter:\n",
    "- Accuracy:  0.9473684210526315\n",
    "- F1 score:  0.9589041095890412\n",
    "\n",
    "max iter:\n",
    "- Accuracy:  0.9473684210526315\n",
    "- F1 score:  0.9594594594594595\n",
    "\n",
    "with scaling \n",
    "- standard\n",
    "    - Accuracy:  0.9736842105263158\n",
    "    - F1 score:  0.9793103448275863\n",
    "- minmax\n",
    "    - Accuracy:  0.9736842105263158\n",
    "    - F1 score:  0.9795918367346939"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Play-Tennis Dataset\n",
    "\n",
    "Load the dataset first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  play\n",
       "3  yes\n",
       "7   no\n",
       "6  yes"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tennis = pd.read_csv('datasets/PlayTennis.csv')\n",
    "X_tennis = tennis.drop(['play'],axis=1)\n",
    "y_tennis = pd.DataFrame(tennis['play'])\n",
    "\n",
    "# Split 80 : 20\n",
    "X_train_tennis, X_valid_tennis, y_train_tennis, y_valid_tennis = train_test_split(X_tennis, y_tennis, train_size = 0.8, test_size = 0.2, random_state=1)\n",
    "y_valid_tennis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether there are missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_with_missing_tennis = [col for col in tennis.columns if tennis[col].isnull().any()]\n",
    "cols_with_missing_tennis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train datasets\n",
    "### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the categorical variable to numeric variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "cond = (X_train_tennis.dtypes == 'object')\n",
    "object_cols = list(cond[cond].index)\n",
    "\n",
    "label_X_train = X_train_tennis.copy()\n",
    "label_X_valid = X_valid_tennis.copy()\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for col in object_cols:\n",
    "    label_X_train[col] = label_encoder.fit_transform(X_train_tennis[col])\n",
    "    label_X_valid[col] = label_encoder.transform(X_valid_tennis[col])\n",
    "\n",
    "# In case needed\n",
    "label_y_train = label_encoder.fit_transform(y_train_tennis)\n",
    "label_y_valid = label_encoder.transform(y_valid_tennis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tennis_classifier = DecisionTreeClassifier(random_state=1)\n",
    "tennis_classifier.fit(label_X_train, y_train_tennis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- outlook <= 0.50\n",
      "|   |--- class: yes\n",
      "|--- outlook >  0.50\n",
      "|   |--- humidity <= 0.50\n",
      "|   |   |--- class: no\n",
      "|   |--- humidity >  0.50\n",
      "|   |   |--- windy <= 0.50\n",
      "|   |   |   |--- class: yes\n",
      "|   |   |--- windy >  0.50\n",
      "|   |   |   |--- outlook <= 1.50\n",
      "|   |   |   |   |--- class: no\n",
      "|   |   |   |--- outlook >  1.50\n",
      "|   |   |   |   |--- class: yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_tennis = export_text(tennis_classifier, feature_names = list(X_tennis.columns))\n",
    "print(tree_tennis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict training data with the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['yes', 'yes', 'yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'yes',\n",
       "       'no'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_train_tennis = tennis_classifier.predict(label_X_train)\n",
    "predict_train_tennis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model to training data with Accuracy Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_train_tennis = accuracy_score(y_train_tennis,predict_train_tennis)\n",
    "acc_train_tennis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model to training data with F1 Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_train_tennis = f1_score(y_train_tennis,predict_train_tennis,pos_label='yes')\n",
    "f1_train_tennis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the test data using model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no', 'no', 'yes'], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_valid_tennis = tennis_classifier.predict(label_X_valid)\n",
    "predict_valid_tennis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model with datatest using Accuracy Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_valid_tennis = accuracy_score(y_valid_tennis,predict_valid_tennis)\n",
    "acc_valid_tennis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model with datatest using F1 Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_valid_tennis = f1_score(y_valid_tennis,predict_valid_tennis,pos_label='yes')\n",
    "f1_valid_tennis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Id3Estimator"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Train the model and print the tree produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "outlook <=0.50: 1 (3) \n",
      "outlook >0.50\n",
      "|   humidity <=0.50: 0 (3) \n",
      "|   humidity >0.50\n",
      "|   |   windy <=0.50: 1 (3) \n",
      "|   |   windy >0.50\n",
      "|   |   |   temp <=1.00: 0 (1) \n",
      "|   |   |   temp >1.00: 1 (1) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "id3_model2 = Id3Estimator()\n",
    "id3_model2.fit(label_X_train, label_y_train)\n",
    "\n",
    "tree_text2 = export.export_text(id3_model2.tree_, feature_names=list(tennis.columns))\n",
    "print(tree_text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model to training data with Accuracy and F1 Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n",
      "F1 score:  1.0\n"
     ]
    }
   ],
   "source": [
    "predict_train2 = id3_model2.predict(label_X_train)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(predict_train2,label_y_train))\n",
    "print(\"F1 score: \", f1_score(predict_train2,label_y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model to test data with using Accuracy and F1 Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6666666666666666\n",
      "F1 score:  0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "predict_test2 = id3_model2.predict(label_X_valid)\n",
    "\n",
    "print(\"Accuracy: \", accuracy_score(predict_test2,label_y_valid))\n",
    "print(\"F1 score: \", f1_score(predict_test2,label_y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define KMeans and then train the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=2, random_state=1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Determine how many clusters\n",
    "n_clst = 2\n",
    "# Define the KMeans\n",
    "kmeans_model_2 = KMeans(n_clusters = n_clst, random_state=1)\n",
    "kmeans_model_2.fit(label_X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict and produce clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = kmeans_model_2.predict(label_X_train)\n",
    "predict_test = kmeans_model_2.predict(label_X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the training data now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First clusterization accuracy: 0.36363636363636365\n",
      "First clusterization F1: 0.4615384615384615\n",
      "Second clusterization accuracy: 0.6363636363636364\n",
      "Second clusterization F1: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Find out each cluster belong with which class\n",
    "\n",
    "# First clusterization using first prediction (k_means_train)\n",
    "# Calculate the accuracy and F1\n",
    "acc_train = accuracy_score(label_y_train, predict_train)\n",
    "f1_train = f1_score(label_y_train, predict_train)\n",
    "print(f\"First clusterization accuracy: {acc_train}\")\n",
    "print(f\"First clusterization F1: {f1_train}\")\n",
    "\n",
    "# Second clusterization: switch 0 to 1\n",
    "switched_train = pd.Series(predict_train)\n",
    "fix = switched_train.apply(switch)\n",
    "acc_train1= accuracy_score(label_y_train, fix)\n",
    "f1_train2= f1_score(label_y_train, fix)\n",
    "print(f\"Second clusterization accuracy: {acc_train1}\")\n",
    "print(f\"Second clusterization F1: {f1_train2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First clusterization is better, so we take the metrics as the final metrics. Evaluate the validation data now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First clusterization accuracy: 0.0\n",
      "First clusterization F1: 0.4615384615384615\n",
      "Second clusterization accuracy: 1.0\n",
      "Second clusterization F1: 1.0\n"
     ]
    }
   ],
   "source": [
    "# First clusterization\n",
    "acc_valid = accuracy_score(label_y_valid, predict_test)\n",
    "f1_valid = f1_score(label_y_valid, predict_test)\n",
    "print(f\"First clusterization accuracy: {acc_valid}\")\n",
    "print(f\"First clusterization F1: {f1_train}\")\n",
    "\n",
    "# Second clusterization: switch 0 to 1\n",
    "switched_valid = pd.Series(predict_test).apply(switch)\n",
    "acc_valid_switch = accuracy_score(label_y_valid, switched_valid)\n",
    "f1_valid_switch = f1_score(label_y_valid, switched_valid)\n",
    "print(f\"Second clusterization accuracy: {acc_valid_switch}\")\n",
    "print(f\"Second clusterization F1: {f1_valid_switch}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as when we evaluate with training data, the first clusterization is better and then will be our final metrics score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scaling if needed\n",
    "# from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "# scaler = MinMaxScaler()\n",
    "\n",
    "# label_X_train = scaler.fit_transform(label_X_train)\n",
    "# label_X_valid = scaler.fit_transform(label_X_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "\n",
    "model.fit(label_X_train,label_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the train data and evaluate the prediction with Accuracy and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.8181818181818182\n",
      "F1 score:  0.8750000000000001\n"
     ]
    }
   ],
   "source": [
    "predict_train = model.predict(label_X_train)\n",
    "\n",
    "acc = accuracy_score(label_y_train, predict_train)\n",
    "f1 = f1_score(label_y_train, predict_train)\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tanpa scaling:\n",
    "- Accuracy:  0.8181818181818182\n",
    "- F1 score:  0.8750000000000001\n",
    "\n",
    "StandardScaler:\n",
    "- Accuracy:  0.9090909090909091\n",
    "- F1 score:  0.9333333333333333\n",
    "\n",
    "MinMaxScaler:\n",
    "- Accuracy:  0.8181818181818182\n",
    "- F1 score:  0.8750000000000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the test data and evaluate the prediction with Accuracy and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6666666666666666\n",
      "F1 score:  0.8\n"
     ]
    }
   ],
   "source": [
    "predict_test = model.predict(label_X_valid)\n",
    "\n",
    "acc = accuracy_score(label_y_valid, predict_test)\n",
    "f1 = f1_score(label_y_valid, predict_test)\n",
    "\n",
    "print(\"Accuracy: \", acc)\n",
    "print(\"F1 score: \", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaada bedanya pake scaling atau engga\n",
    "- Accuracy:  0.6666666666666666\n",
    "- F1 score:  0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
